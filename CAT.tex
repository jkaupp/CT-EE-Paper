\subsection{The Critical Thinking Assessment Test}

The Critical Thinking Assessment Test (CAT) was developed collaboratively by Tennessee Technological University (TTU) and faculty from participating institutions. The primary goal of this collaboration was to develop a faculty-driven assessment tool to engage the faculty in meaningful, authentic assessment with the goal of improving student learning. The CAT differs from most critical thinking tests in that it does not subscribe to a singular framework describing critical thinking. In a manner similar to the development of the APA Delphi model, the CAT is based around a consensus core set of four skills that comprise critical thinking across a variety of disciplines and 12 representative areas in which to assess these skills \cite{Stein:2011hr}:

1)	Evaluating Information
a.	Separate factual information from inferences
b.	Interpret numerical relationships in graphs
c.	Understand the limitations of correlational data
d.	Evaluate evidence and identify inappropriate conclusions
2)	Creative Thinking
a.	Identify alternative interpretations for data or observations
b.	Identify new information that might support or contradict an hypothesis
c.	Explain how new information can change a problem		
3)	Learning and Problem Solving
a.	Separate relevant from irrelevant information
b.	Integrate information to solve problems
c.	Learn and apply new information
d.	Use mathematical skills to solve real-world problems
4)	Communication
a.	Communicate ideas effectively

The CAT consists of 15 questions requiring both quick-response items (multiple choice, binary scale) and short-answer essay responses that are likely to measure the cognitive elements of critical thinking and some dispositional elements through its open-ended prompts \cite{Ku:2009uj}. Currently, the CAT is a paper-based test, with plans to move to a digital delivery system in the near future. The participating institutions own faculty score the CAT, through a “train-the-trainer” system and following a detailed scoring rubric. Validity and reliability measures have been published, achieving face and criterion validity through expert review of the instrument and correlation measures (r>0.5, p<0.01) with academic measures (Scholastic Aptitude Test, SAT and the American College Testing College Readiness Assessment, ACT), other tools (National Survey of Student Engagement, NSSE) and other critical thinking tests (Collegiate Assessment of Academic Proficiency Critical Thinking Module, CCTST). Reliability was assessed through test-retest reliability (r>0.80), inter-rater reliability (kappa=0.82) and Cronbach’s alpha (α=0.695) (“CAT Instrument Technical Information,” 2010; Stein, Haynes & Redding, 2008; Stein, Haynes, Redding, Ennis & Cecil, 2007; Stein, Haynes & Redding, 2006). Despite the relative infancy of the tool, several studies have used the CAT (Gasper & Gardner, 2013; Gottesman & Hoskins, 2013) alongside many National Science Foundation (NSF)-funded initiatives (“Successful Projects | Tennessee Tech University,” n.d.).
